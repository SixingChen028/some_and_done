{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_to_trials(raw, num_trial):\n",
    "    \"\"\"\n",
    "    Parse raw data to trials.\n",
    "    \"\"\"\n",
    "\n",
    "    trials = [[] for _ in range(num_trial)]\n",
    "    main_flag = False\n",
    "    trial_index = 0\n",
    "\n",
    "    # loop through events\n",
    "    for event in raw:\n",
    "\n",
    "        # if in the main exp\n",
    "        if main_flag:\n",
    "\n",
    "            # update trial index\n",
    "            if 'trial_index' in event.keys():\n",
    "                trial_index = event['trial_index']\n",
    "\n",
    "            # log event to trial\n",
    "            trials[trial_index].append(event)\n",
    "        \n",
    "        # enter the main exp\n",
    "        if event['event'] == 'timeline.start.main':\n",
    "            main_flag = True\n",
    "\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trials_to_data(trials):\n",
    "    \"\"\"\n",
    "    Parse trials to data.\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\n",
    "        'graphs': [],\n",
    "        'rewards': [],\n",
    "        'starts': [],\n",
    "        'hover_limits': [],\n",
    "        'hover_seqs': [],\n",
    "        'visit_seqs': [],\n",
    "        'rollout_lengths': [],\n",
    "    }\n",
    "\n",
    "    # loop through trials\n",
    "    for trial in trials:\n",
    "        # loop through events in the trial\n",
    "        for event in trial:\n",
    "\n",
    "            # new trial\n",
    "            if 'graph' in event.keys():\n",
    "                # initialize trial recording\n",
    "                hover_seq = []\n",
    "                visit_seq = []\n",
    "\n",
    "                # log trial info\n",
    "                data['graphs'].append(event['graph'])\n",
    "                data['rewards'].append(event['rewards'])\n",
    "                data['starts'].append(event['start'])\n",
    "                data['hover_limits'].append(event['hover_limit'])\n",
    "            \n",
    "            # imagination\n",
    "            if event['event'] == 'graph.imagine':\n",
    "                hover_seq.append(event['state'])\n",
    "            \n",
    "            # navigation\n",
    "            if event['event'] == 'graph.visit':\n",
    "                visit_seq.append(event['state'])\n",
    "        \n",
    "        # log trial info\n",
    "        data['hover_seqs'].append(hover_seq)\n",
    "        data['visit_seqs'].append(visit_seq)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wff0e37f\n",
      "w64a20fb\n",
      "w930df1c\n",
      "w1136569\n",
      "w5f0a4e2\n",
      "we52e417\n",
      "w4ee306c\n",
      "waa3a4a4\n",
      "w3ba63d6\n",
      "w1206510\n",
      "w2ce5641\n",
      "wfc8657f\n",
      "w6cba169\n",
      "w3c4d8b1\n",
      "waec10f6\n",
      "wf3bd4f2\n",
      "w4431e3b\n",
      "w4fd295b\n",
      "w651bd37\n",
      "w7425c1c\n"
     ]
    }
   ],
   "source": [
    "num_trial = 100\n",
    "\n",
    "# directory\n",
    "dir_load = 'data/data_raw'\n",
    "dir_save = 'data/data_processed'\n",
    "\n",
    "# subj id list\n",
    "# id_list = ['wa0b5c62', 'w0b569b1', 'w3efaab9', 'w5a2c6c0', 'wb67e511', 'w83a6669']#, 'wd72ec4f']\n",
    "id_list = [\n",
    "    'wff0e37f',\n",
    "    'w64a20fb',\n",
    "    'w930df1c',\n",
    "    'w1136569',\n",
    "    'w5f0a4e2',\n",
    "    'we52e417',\n",
    "    'w4ee306c',\n",
    "    'waa3a4a4',\n",
    "    'w3ba63d6',\n",
    "    'w1206510',\n",
    "    'w2ce5641',\n",
    "    'wfc8657f',\n",
    "    'w6cba169',\n",
    "    'w3c4d8b1',\n",
    "    'waec10f6',\n",
    "    'wf3bd4f2',\n",
    "    'w4431e3b',\n",
    "    'w4fd295b',\n",
    "    'w651bd37',\n",
    "    'w7425c1c'\n",
    "]\n",
    "\n",
    "# loop through subjects\n",
    "for id in id_list:\n",
    "    print(id)\n",
    "    # load data\n",
    "    with open(f'{dir_load}/{id}.json', 'r', encoding = 'utf-8') as file:\n",
    "        raw_subj = json.load(file)\n",
    "\n",
    "    # parse trials\n",
    "    trials_subj = parse_raw_to_trials(raw_subj, num_trial)\n",
    "\n",
    "    # process data\n",
    "    data_subj = parse_trials_to_data(trials_subj)\n",
    "\n",
    "    # further processing\n",
    "    data_subj['max_depths'] = []\n",
    "    data_subj['child_dicts'] = []\n",
    "    data_subj['hover_counts'] = []\n",
    "    data_subj['rollout_counts'] = []\n",
    "    data_subj['cum_rewards'] = []\n",
    "    data_subj['action_values'] = []\n",
    "\n",
    "    for i in range(num_trial):\n",
    "\n",
    "        # add max depth and child dict\n",
    "        data_subj['max_depths'].append(max_depth(data_subj['graphs'][i], data_subj['starts'][i]))\n",
    "        data_subj['child_dicts'].append(list_to_dict(data_subj['graphs'][i]))\n",
    "\n",
    "        # remove repeating nodes\n",
    "        data_subj['hover_seqs'][i] = merge_adjacent(data_subj['hover_seqs'][i])\n",
    "        data_subj['visit_seqs'][i] = merge_adjacent(data_subj['visit_seqs'][i])\n",
    "\n",
    "        # remove nodes not in the tree\n",
    "        data_subj['hover_seqs'][i] = [node for node in data_subj['hover_seqs'][i] if is_node_in_tree(node, data_subj['child_dicts'][i])]\n",
    "\n",
    "        # # insert root node\n",
    "        # if data_subj['imagine_seqs'][i][0] != data_subj['starts'][i]:\n",
    "        #     data_subj['imagine_seqs'][i].insert(0, data_subj['starts'][i])\n",
    "\n",
    "        # remove last node\n",
    "        if len(data_subj['hover_seqs'][i]) > 1 and data_subj['hover_seqs'][i][-1] == data_subj['starts'][i]:\n",
    "            data_subj['hover_seqs'][i].pop()\n",
    "        \n",
    "        # add depths\n",
    "        # data_subj['depths'].append([get_depth(node, data_subj['child_dicts'][i], data_subj['starts'][i]) for node in range(len(data_subj['graphs'][i]))])\n",
    "        # data_subj['depth_seqs'].append([get_depth(node, data_subj['child_dicts'][i], data_subj['starts'][i]) for node in data_subj['imagine_seqs'][i]])\n",
    "\n",
    "        # add hover numbers\n",
    "        data_subj['hover_counts'].append(len(data_subj['hover_seqs'][i]))\n",
    "        data_subj['rollout_counts'].append(data_subj['hover_seqs'][i].count(data_subj['starts'][i]))\n",
    "        data_subj['rollout_lengths'].append(segment_lengths(data_subj['hover_seqs'][i], data_subj['starts'][i]))\n",
    "\n",
    "        # add cumulative rewards\n",
    "        data_subj['cum_rewards'].append(sum([data_subj['rewards'][i][node] for node in data_subj['visit_seqs'][i]]))\n",
    "\n",
    "        # add action values\n",
    "        depth_1_nodes = data_subj['child_dicts'][i][data_subj['starts'][i]]\n",
    "        data_subj['action_values'].append([get_action_value(node, data_subj['child_dicts'][i], data_subj['rewards'][i]) for node in depth_1_nodes])\n",
    "\n",
    "    # save data\n",
    "    pickle.dump(data_subj, open(f'{dir_save}/{id}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
